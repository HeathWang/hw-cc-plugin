#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸…ç†æœªä½¿ç”¨çš„å›½é™…åŒ–å­—ç¬¦ä¸²è„šæœ¬

è¿™ä¸ªè„šæœ¬ä¼šï¼š
1. è§£æ Localizable.strings æ–‡ä»¶ï¼Œæå–æ‰€æœ‰çš„å›½é™…åŒ–é”®å€¼å¯¹
2. å°†åŸå§‹é”®ï¼ˆsnake_caseï¼‰è½¬æ¢ä¸º SwiftGen ç”Ÿæˆçš„ camelCase æ ¼å¼
3. åœ¨é¡¹ç›®ä»£ç ä¸­æœç´¢æ¯ä¸ª L10n.camelCaseKey çš„å¼•ç”¨
4. åˆ é™¤æœªä½¿ç”¨çš„å›½é™…åŒ–æ¡ç›®
5. ç”Ÿæˆæ¸…ç†æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•:
python3 clean_unused_localizations.py [--dry-run] [--verbose]

å‚æ•°ï¼š
--dry-run: åªæ˜¾ç¤ºä¼šåˆ é™¤çš„æ¡ç›®ï¼Œä¸å®é™…ä¿®æ”¹æ–‡ä»¶
--verbose: æ˜¾ç¤ºè¯¦ç»†çš„æœç´¢è¿‡ç¨‹
"""

import re
import os
import sys
import argparse
from pathlib import Path
from typing import Dict, List, Tuple, Set
import subprocess

class LocalizationCleaner:
    def __init__(self, project_root: str, localizable_file: str = None, source_dir: str = None,
                 dry_run: bool = False, verbose: bool = False):
        self.project_root = Path(project_root)
        self.dry_run = dry_run
        self.verbose = verbose

        # Use provided paths or fall back to defaults
        if localizable_file:
            self.localizable_file = Path(localizable_file)
        else:
            # Default: search for Localizable.strings in common locations
            self.localizable_file = self._find_localizable_file()

        if source_dir:
            self.source_dir = Path(source_dir)
        else:
            # Default: use project root or common subdirectory
            self.source_dir = self._find_source_dir()

        # éœ€è¦æœç´¢çš„æ–‡ä»¶æ‰©å±•å
        self.search_extensions = ['.swift', '.m', '.mm', '.h']

    def _find_localizable_file(self) -> Path:
        """Search for Localizable.strings in common locations"""
        common_paths = [
            self.project_root / "Resources" / "Localization" / "en.lproj" / "Localizable.strings",
            self.project_root / "Resources" / "Localization" / "zh-Hans.lproj" / "Localizable.strings",
            self.project_root / "Localization" / "en.lproj" / "Localizable.strings",
        ]

        for path in common_paths:
            if path.exists():
                print(f"Found localization file: {path}")
                return path

        # If not found, raise error with helpful message
        raise FileNotFoundError(
            f"Cannot find Localizable.strings automatically. "
            f"Please specify using --localizable-file parameter. "
            f"Common locations checked: {[str(p) for p in common_paths]}"
        )

    def _find_source_dir(self) -> Path:
        """Find the source code directory"""
        common_dirs = [
            self.project_root,
            self.project_root / "Sources",
            self.project_root / "App",
        ]

        for dir_path in common_dirs:
            if dir_path.exists() and any(dir_path.rglob(f'*{self.search_extensions[0]}')):
                print(f"Using source directory: {dir_path}")
                return dir_path

        # Default to project root
        print(f"Using project root as source directory: {self.project_root}")
        return self.project_root
        
    def snake_to_camel(self, snake_str: str) -> str:
        """
        å°†é”®åè½¬æ¢ä¸º SwiftGen ç”Ÿæˆçš„æ ¼å¼

        SwiftGen çš„å‘½åè§„åˆ™ï¼ˆåŸºäº .claude/commands/translate-cn.mdï¼‰ï¼š
        1. é”®åæŒ‰ç‚¹å·åˆ†å‰²ï¼šcommon.ok â†’ ['common', 'ok']
        2. é™¤æœ€åä¸€ä¸ªéƒ¨åˆ†å¤–ï¼Œæ¯ä¸ªéƒ¨åˆ†é¦–å­—æ¯å¤§å†™ï¼ˆTitle Caseï¼‰ï¼š['Common', 'ok']
        3. æœ€åä¸€ä¸ªéƒ¨åˆ†å¦‚æœæ˜¯ snake_caseï¼ˆåŒ…å«ä¸‹åˆ’çº¿ï¼‰ï¼Œè½¬æ¢ä¸º camelCase
        4. ç”¨ç‚¹å·è¿æ¥ï¼šCommon.ok
        5. æœ€ç»ˆåœ¨ä»£ç ä¸­ä½¿ç”¨ï¼šL10n.Common.ok

        ç¤ºä¾‹ï¼ˆæ¥è‡ª translate-cn.mdï¼‰ï¼š
        - common.ok â†’ L10n.Common.ok
        - market.back â†’ L10n.Market.back
        - market.header.name â†’ L10n.Market.Header.name
        - addbalance.flashexchange.subtitle â†’ L10n.Addbalance.Flashexchange.subtitle
        - futuresrecords.header.amount_usdt â†’ L10n.Futuresrecords.Header.amountUsdt

        é‡è¦è¯´æ˜ï¼š
        - å¤åˆè¯ï¼ˆflashexchangeï¼‰åªé¦–å­—æ¯å¤§å†™ï¼šFlashexchangeï¼Œè€Œé FlashExchange
        - åµŒå¥—é”®ï¼ˆinprogressï¼‰åªé¦–å­—æ¯å¤§å†™ï¼šInprogressï¼Œè€Œé InProgress
        - æœ€åä¸€çº§çš„ snake_case è½¬æ¢ä¸º camelCaseï¼šamount_usdt â†’ amountUsdt
        """
        # å…ˆæŒ‰ç‚¹å·åˆ†å‰²
        parts = snake_str.split('.')

        # å¯¹é™¤æœ€åä¸€ä¸ªéƒ¨åˆ†å¤–çš„æ‰€æœ‰éƒ¨åˆ†è¿›è¡Œé¦–å­—æ¯å¤§å†™ï¼ˆTitle Caseï¼‰
        result_parts = []
        for i, part in enumerate(parts):
            if i == len(parts) - 1:
                # æœ€åä¸€ä¸ªéƒ¨åˆ†éœ€è¦ç‰¹æ®Šå¤„ç†
                # å¦‚æœåŒ…å«ä¸‹åˆ’çº¿ï¼ˆsnake_caseï¼‰ï¼Œè½¬æ¢ä¸º camelCase
                if '_' in part:
                    # snake_case â†’ camelCase
                    sub_parts = part.split('_')
                    camel_case = sub_parts[0] + ''.join(word.capitalize() for word in sub_parts[1:])
                    result_parts.append(camel_case)
                else:
                    # æ²¡æœ‰ä¸‹åˆ’çº¿ï¼Œä¿æŒåŸæ ·
                    result_parts.append(part)
            else:
                # å…¶ä»–éƒ¨åˆ†é¦–å­—æ¯å¤§å†™ï¼ˆTitle Caseï¼Œåªå¤§å†™é¦–å­—æ¯ï¼‰
                result_parts.append(part[0].upper() + part[1:] if part else part)

        return '.'.join(result_parts)
    
    def parse_localizable_strings(self) -> Dict[str, Tuple[str, str]]:
        """
        è§£æ Localizable.strings æ–‡ä»¶
        è¿”å›: {original_key: (camel_case_key, value)}
        """
        if not self.localizable_file.exists():
            raise FileNotFoundError(f"Localizable.strings æ–‡ä»¶ä¸å­˜åœ¨: {self.localizable_file}")
            
        localizations = {}
        
        with open(self.localizable_file, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # åŒ¹é… "key" = "value"; æ ¼å¼çš„è¡Œ
        # æ”¯æŒé”®åä¸­çš„ç‚¹å·ï¼ˆå¦‚ common.okï¼‰å’Œå€¼ä¸­çš„è½¬ä¹‰å­—ç¬¦
        pattern = r'^\s*"([a-zA-Z0-9_.-]+)"\s*=\s*"((?:[^"\\]|\\.)*)"\s*;\s*$'
        
        for line_num, line in enumerate(content.splitlines(), 1):
            line = line.strip()
            
            # è·³è¿‡æ³¨é‡Šå’Œç©ºè¡Œ
            if not line or line.startswith('//'):
                continue
                
            match = re.match(pattern, line)
            if match:
                original_key = match.group(1)
                value = match.group(2)
                camel_case_key = self.snake_to_camel(original_key)
                localizations[original_key] = (camel_case_key, value)
                
                if self.verbose:
                    print(f"è§£æ: {original_key} -> L10n.{camel_case_key}")
            else:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„æœ¬åœ°åŒ–è¡Œä½†æ ¼å¼ä¸åŒ¹é…
                if '"' in line and '=' in line and ';' in line:
                    print(f"è­¦å‘Š: ç¬¬{line_num}è¡Œæ ¼å¼å¯èƒ½æœ‰é—®é¢˜: {line}")
        
        print(f"æ€»å…±è§£æäº† {len(localizations)} ä¸ªå›½é™…åŒ–æ¡ç›®")
        return localizations
    
    def find_swift_files(self) -> List[Path]:
        """æŸ¥æ‰¾æ‰€æœ‰éœ€è¦æœç´¢çš„æºç æ–‡ä»¶"""
        files = []
        for ext in self.search_extensions:
            files.extend(self.source_dir.rglob(f'*{ext}'))
        
        # æ’é™¤ä¸€äº›ä¸éœ€è¦æœç´¢çš„ç›®å½•
        excluded_dirs = {'Pods', 'build', 'DerivedData', '.git'}
        filtered_files = []
        
        for file in files:
            # æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦åŒ…å«æ’é™¤çš„ç›®å½•
            if not any(excluded_dir in file.parts for excluded_dir in excluded_dirs):
                filtered_files.append(file)
        
        return filtered_files
    
    def search_in_file(self, file_path: Path, search_term: str) -> bool:
        """åœ¨æ–‡ä»¶ä¸­æœç´¢æŒ‡å®šçš„å­—ç¬¦ä¸²"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                return search_term in content
        except Exception as e:
            if self.verbose:
                print(f"è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
            return False
    
    def is_localization_used(self, original_key: str, camel_case_key: str, swift_files: List[Path]) -> Tuple[bool, List[Path], str]:
        """
        æ£€æŸ¥æœ¬åœ°åŒ–é”®æ˜¯å¦åœ¨ä»£ç ä¸­è¢«ä½¿ç”¨ã€‚
        ä¼˜åŒ–ï¼šæ‰¾åˆ°ä»»ä½•ä¸€ä¸ªä½¿ç”¨å®ä¾‹åç«‹å³è¿”å›ï¼Œæé«˜æ•ˆç‡ã€‚
        è¿”å›: (æ˜¯å¦ä½¿ç”¨, ä½¿ç”¨çš„æ–‡ä»¶åˆ—è¡¨, ä½¿ç”¨æ–¹å¼)
        """
        # 1. é¦–å…ˆæ£€æŸ¥ SwiftGen æ–¹å¼: L10n.camelCaseKey
        swiftgen_term = f"L10n.{camel_case_key}"
        for file_path in swift_files:
            if self.search_in_file(file_path, swiftgen_term):
                return True, [file_path], "SwiftGen"

        # 2. å¦‚æœ SwiftGen æ–¹å¼æ²¡æœ‰æ‰¾åˆ°ï¼Œå†æ£€æŸ¥åŸç”Ÿæ–¹å¼
        # Objective-C: NSLocalizedString(@"key"
        native_term_oc = f'NSLocalizedString(@"{original_key}"'
        # Swift: NSLocalizedString("key"
        native_term_swift = f'NSLocalizedString("{original_key}"'

        for file_path in swift_files:
            # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©ä¸åŒçš„æœç´¢æ¨¡å¼
            if file_path.suffix in ['.m', '.mm', '.h']:
                if self.search_in_file(file_path, native_term_oc):
                    return True, [file_path], "NSLocalizedString"
            elif file_path.suffix == '.swift':
                if self.search_in_file(file_path, native_term_swift):
                    return True, [file_path], "NSLocalizedString"
                # Swift æ–‡ä»¶ä¹Ÿå¯èƒ½åŒ…å« OC çš„æ ¼å¼ï¼Œä»¥é˜²ä¸‡ä¸€
                if self.search_in_file(file_path, native_term_oc):
                    return True, [file_path], "NSLocalizedString"
        
        return False, [], ""
    
    def find_unused_localizations(self, localizations: Dict[str, Tuple[str, str]]) -> Tuple[Dict[str, Tuple[str, str]], Dict[str, Tuple[str, str, str]]]:
        """
        æ‰¾å‡ºæœªä½¿ç”¨çš„æœ¬åœ°åŒ–æ¡ç›®
        è¿”å›: (æœªä½¿ç”¨çš„æ¡ç›®, å·²ä½¿ç”¨çš„æ¡ç›®è¯¦æƒ…)
        """
        unused = {}
        used_details = {}  # {original_key: (camel_case_key, value, usage_type)}
        total = len(localizations)
        
        print("å¼€å§‹æœç´¢æœªä½¿ç”¨çš„å›½é™…åŒ–æ¡ç›®...")
        swift_files = self.find_swift_files()
        
        for i, (original_key, (camel_case_key, value)) in enumerate(localizations.items(), 1):
            if self.verbose:
                print(f"æ£€æŸ¥ ({i}/{total}): L10n.{camel_case_key} / NSLocalizedString(\"{original_key}\"")
            else:
                # æ˜¾ç¤ºè¿›åº¦
                if i % 50 == 0 or i == total:
                    print(f"è¿›åº¦: {i}/{total}")
            
            is_used, used_files, usage_type = self.is_localization_used(original_key, camel_case_key, swift_files)
            
            if not is_used:
                unused[original_key] = (camel_case_key, value)
                if self.verbose:
                    print(f"  âŒ æœªä½¿ç”¨: {original_key}")
            else:
                used_details[original_key] = (camel_case_key, value, usage_type)
                if self.verbose:
                    # å› ä¸º is_localization_used åªè¿”å›ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„æ–‡ä»¶ï¼Œæ‰€ä»¥ used_files[0] æ˜¯å®‰å…¨çš„
                    print(f"  âœ… å·²ä½¿ç”¨: {original_key} (æ–¹å¼: {usage_type}, åœ¨ {used_files[0].name} ä¸­æ‰¾åˆ°)")
        
        return unused, used_details
    
    def remove_unused_localizations(self, unused_keys: Set[str]) -> bool:
        """ä» Localizable.strings æ–‡ä»¶ä¸­åˆ é™¤æœªä½¿ç”¨çš„æ¡ç›®"""
        if not unused_keys:
            print("æ²¡æœ‰æ‰¾åˆ°æœªä½¿ç”¨çš„å›½é™…åŒ–æ¡ç›®")
            return True
            
        if self.dry_run:
            print(f"[DRY RUN] å°†ä¼šåˆ é™¤ {len(unused_keys)} ä¸ªæœªä½¿ç”¨çš„æ¡ç›®")
            return True
        
        try:
            with open(self.localizable_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # åˆ›å»ºå¤‡ä»½
            backup_file = self.localizable_file.with_suffix('.strings.backup')
            with open(backup_file, 'w', encoding='utf-8') as f:
                f.writelines(lines)
            print(f"å·²åˆ›å»ºå¤‡ä»½æ–‡ä»¶: {backup_file}")
            
            # è¿‡æ»¤æ‰æœªä½¿ç”¨çš„æ¡ç›®
            filtered_lines = []
            removed_count = 0
            
            for line in lines:
                line_stripped = line.strip()
                
                # å¦‚æœæ˜¯ç©ºè¡Œæˆ–æ³¨é‡Šï¼Œä¿ç•™
                if not line_stripped or line_stripped.startswith('//'):
                    filtered_lines.append(line)
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯è¦åˆ é™¤çš„æœ¬åœ°åŒ–æ¡ç›®
                match = re.match(r'^\s*"([a-zA-Z0-9_.-]+)"\s*=\s*"(?:[^"\\]|\\.)*"\s*;\s*$', line_stripped)
                if match:
                    key = match.group(1)
                    if key in unused_keys:
                        removed_count += 1
                        if self.verbose:
                            print(f"åˆ é™¤: {line_stripped}")
                        continue
                
                filtered_lines.append(line)
            
            # å†™å›æ–‡ä»¶
            with open(self.localizable_file, 'w', encoding='utf-8') as f:
                f.writelines(filtered_lines)
            
            print(f"æˆåŠŸåˆ é™¤äº† {removed_count} ä¸ªæœªä½¿ç”¨çš„å›½é™…åŒ–æ¡ç›®")
            return True
            
        except Exception as e:
            print(f"åˆ é™¤æœªä½¿ç”¨æ¡ç›®æ—¶å‡ºé”™: {e}")
            return False
    
    def generate_report(self, localizations: Dict[str, Tuple[str, str]], unused: Dict[str, Tuple[str, str]], used_details: Dict[str, Tuple[str, str, str]]):
        """ç”Ÿæˆæ¸…ç†æŠ¥å‘Š"""
        report_file = self.project_root / "localization_cleanup_report.txt"
        
        # ç»Ÿè®¡ä½¿ç”¨æ–¹å¼
        swiftgen_count = sum(1 for details in used_details.values() if details[2] == "SwiftGen")
        nslocalizedstring_count = sum(1 for details in used_details.values() if details[2] == "NSLocalizedString")
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("å›½é™…åŒ–å­—ç¬¦ä¸²æ¸…ç†æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"é¡¹ç›®è·¯å¾„: {self.project_root}\n")
            f.write(f"æœ¬åœ°åŒ–æ–‡ä»¶: {self.localizable_file}\n")
            f.write(f"æ‰«ææ—¶é—´: {__import__('datetime').datetime.now()}\n\n")
            
            f.write("ç»Ÿè®¡ä¿¡æ¯:\n")
            f.write("-" * 20 + "\n")
            f.write(f"æ€»è®¡å›½é™…åŒ–æ¡ç›®: {len(localizations)}\n")
            f.write(f"å·²ä½¿ç”¨æ¡ç›®: {len(used_details)}\n")
            f.write(f"  - SwiftGen æ–¹å¼ (L10n.xxx): {swiftgen_count}\n")
            f.write(f"  - åŸç”Ÿæ–¹å¼ (NSLocalizedString): {nslocalizedstring_count}\n")
            f.write(f"æœªä½¿ç”¨æ¡ç›®: {len(unused)}\n")
            f.write(f"ä½¿ç”¨ç‡: {((len(localizations) - len(unused)) / len(localizations) * 100):.1f}%\n\n")
            
            if unused:
                f.write("\nå®Œå…¨æœªä½¿ç”¨çš„å›½é™…åŒ–æ¡ç›®:\n")
                f.write("=" * 30 + "\n")
                for original_key, (camel_case_key, value) in unused.items():
                    f.write(f'"{original_key}" = "{value}";\n')
            else:
                f.write("\næ­å–œï¼æ²¡æœ‰å‘ç°æœªä½¿ç”¨çš„å›½é™…åŒ–æ¡ç›®ã€‚\n")
        
        print(f"å·²ç”Ÿæˆæ¸…ç†æŠ¥å‘Š: {report_file}")
        
        # æ§åˆ¶å°è¾“å‡ºä½¿ç”¨æ–¹å¼ç»Ÿè®¡
        if used_details:
            print(f"\nä½¿ç”¨æ–¹å¼ç»Ÿè®¡:")
            print(f"  SwiftGen æ–¹å¼: {swiftgen_count} ä¸ª")
            print(f"  NSLocalizedString æ–¹å¼: {nslocalizedstring_count} ä¸ª")
            
            if nslocalizedstring_count > 0:
                print(f"\nğŸ’¡ å»ºè®®: å‘ç° {nslocalizedstring_count} ä¸ªä½¿ç”¨åŸç”Ÿ NSLocalizedString çš„æ¡ç›®")
                print("   ä¸ºäº†ä¿æŒä»£ç ä¸€è‡´æ€§ï¼Œå»ºè®®å°†å®ƒä»¬æ”¹ä¸ºä½¿ç”¨ SwiftGen ç”Ÿæˆçš„ L10n.xxx å½¢å¼")
    
    def run(self):
        """æ‰§è¡Œæ¸…ç†æµç¨‹"""
        print(f"å¼€å§‹æ¸…ç†å›½é™…åŒ–å­—ç¬¦ä¸²...")
        print(f"é¡¹ç›®è·¯å¾„: {self.project_root}")
        print(f"æœ¬åœ°åŒ–æ–‡ä»¶: {self.localizable_file}")
        print(f"æ¨¡å¼: {'DRY RUN' if self.dry_run else 'REAL RUN'}")
        print()
        
        # 1. è§£ææœ¬åœ°åŒ–æ–‡ä»¶
        try:
            localizations = self.parse_localizable_strings()
        except Exception as e:
            print(f"è§£ææœ¬åœ°åŒ–æ–‡ä»¶å¤±è´¥: {e}")
            return False
        
        if not localizations:
            print("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å›½é™…åŒ–æ¡ç›®")
            return False
        
        # 2. æŸ¥æ‰¾æœªä½¿ç”¨çš„æ¡ç›®
        unused, used_details = self.find_unused_localizations(localizations)
        
        # 3. ç”ŸæˆæŠ¥å‘Š
        self.generate_report(localizations, unused, used_details)
        
        # 4. æ˜¾ç¤ºç»“æœ
        print(f"\næ¸…ç†ç»“æœ:")
        print(f"æ€»è®¡æ¡ç›®: {len(localizations)}")
        print(f"æœªä½¿ç”¨æ¡ç›®: {len(unused)}")
        print(f"ä½¿ç”¨ç‡: {((len(localizations) - len(unused)) / len(localizations) * 100):.1f}%")
        
        if unused:
            print(f"\nå‘ç° {len(unused)} ä¸ªæœªä½¿ç”¨çš„æ¡ç›®:")
            for original_key, (camel_case_key, value) in unused.items():
                print(f'  "{original_key}" = "{value}";')
        
        # 5. åˆ é™¤æœªä½¿ç”¨çš„æ¡ç›®
        if unused:
            if self.dry_run:
                print(f"\n[DRY RUN] å¦‚æœæ‰§è¡Œæ¸…ç†ï¼Œå°†åˆ é™¤ {len(unused)} ä¸ªæœªä½¿ç”¨çš„æ¡ç›®")
            else:
                confirm = input(f"\nç¡®å®šè¦åˆ é™¤è¿™ {len(unused)} ä¸ªæœªä½¿ç”¨çš„æ¡ç›®å—? (y/N): ")
                if confirm.lower() == 'y':
                    success = self.remove_unused_localizations(set(unused.keys()))
                    if success:
                        print("æ¸…ç†å®Œæˆï¼è¯·è®°å¾—è¿è¡Œ SwiftGen é‡æ–°ç”Ÿæˆ Strings.swift æ–‡ä»¶:")
                        print("swiftgen config run --config swiftgen.yml")
                    return success
                else:
                    print("å–æ¶ˆæ¸…ç†æ“ä½œ")
        else:
            print("\næ²¡æœ‰æœªä½¿ç”¨çš„å›½é™…åŒ–æ¡ç›®ï¼Œæ— éœ€æ¸…ç†")
        
        return True

def main():
    parser = argparse.ArgumentParser(
        description='æ¸…ç†æœªä½¿ç”¨çš„å›½é™…åŒ–å­—ç¬¦ä¸²',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # è‡ªåŠ¨æŸ¥æ‰¾ Localizable.stringsï¼ˆåœ¨å¸¸è§ä½ç½®ï¼‰
  python3 clean_unused_localizations.py

  # æŒ‡å®šæœ¬åœ°åŒ–æ–‡ä»¶è·¯å¾„
  python3 clean_unused_localizations.py --localizable-file /path/to/Localizable.strings

  # æŒ‡å®šé¡¹ç›®æ ¹ç›®å½•å’Œæºç ç›®å½•
  python3 clean_unused_localizations.py --project-root /path/to/project --source-dir /path/to/project/Sources

  # é¢„è§ˆæ¨¡å¼ï¼ˆä¸å®é™…ä¿®æ”¹æ–‡ä»¶ï¼‰
  python3 clean_unused_localizations.py --dry-run
        """
    )
    parser.add_argument('--dry-run', action='store_true', help='åªæ˜¾ç¤ºä¼šåˆ é™¤çš„æ¡ç›®ï¼Œä¸å®é™…ä¿®æ”¹æ–‡ä»¶')
    parser.add_argument('--verbose', '-v', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†çš„æœç´¢è¿‡ç¨‹')
    parser.add_argument('--project-root', default='.', help='é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ (é»˜è®¤: å½“å‰ç›®å½•)')
    parser.add_argument('--localizable-file', help='Localizable.strings æ–‡ä»¶çš„å®Œæ•´è·¯å¾„ (å¯é€‰ï¼Œè‡ªåŠ¨æŸ¥æ‰¾)')
    parser.add_argument('--source-dir', help='æºä»£ç ç›®å½•è·¯å¾„ (å¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨æŸ¥æ‰¾)')

    args = parser.parse_args()

    # æ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•
    project_root = Path(args.project_root).resolve()
    if not project_root.exists():
        print(f"é”™è¯¯: é¡¹ç›®è·¯å¾„ä¸å­˜åœ¨: {project_root}")
        sys.exit(1)

    # åˆ›å»ºæ¸…ç†å™¨å¹¶æ‰§è¡Œ
    try:
        cleaner = LocalizationCleaner(
            project_root=str(project_root),
            localizable_file=args.localizable_file,
            source_dir=args.source_dir,
            dry_run=args.dry_run,
            verbose=args.verbose
        )

        success = cleaner.run()
        sys.exit(0 if success else 1)
    except FileNotFoundError as e:
        print(f"é”™è¯¯: {e}")
        sys.exit(1)
    except KeyboardInterrupt:
        print("\nç”¨æˆ·å–æ¶ˆæ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
